# -*- coding: utf-8 -*-
"""Multilayer_perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lh-T2OTNtPvJhEGrjiKB_J1U4lqkfTfo
"""

# Import thư viện cần thiết
from os import listdir
import cv2
import numpy as np
import pickle

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

from keras.layers import Input, Flatten, Dense, Dropout
from keras.models import Model

import matplotlib.pyplot as plt
import random

# Đường dẫn tới thư mục chứa ảnh dùng để train
data_folder = "/content/drive/MyDrive/fruit/Training"

# Hàm tạo data bao gồm các hình ảnh trong thư mục và gán nhãn 
def save_data(data_folder=data_folder):

    img_size = (64, 64)
    print("Bắt đầu thêm ảnh...")

    images = []
    labels = []
    names = []

    # Đọc các thư mục con trong folder data
    for folder in listdir(data_folder):
        if folder!='.DS_Store':
            print(folder)
            names.append(folder)
            # Đọc các file trong thư mục con và lưu hình vào images, nhãn vào label
            for file in listdir(data_folder  + folder):
                if file!='.DS_Store':
                    images.append(cv2.resize(cv2.imread(data_folder  + folder +"/" + file),dsize=(64,64)))
                    labels.append(folder)

    images = np.array(images)
    labels = np.array(labels)#.reshape(-1,1)

    from sklearn.preprocessing import LabelBinarizer
    encoder = LabelBinarizer()
    labels = encoder.fit_transform(labels)
    print(labels)

    file1 = open('/content/drive/MyDriv/fruit/fruit-train.data','wb')
    file2 = open('/content/drive/MyDrive/fruit/fruit-train-class.data','wb')
    # dump information to that file
    pickle.dump((images,labels), file1)
    pickle.dump(names, file2)
    # close the file
    file1.close()
    file2.close()

    return



# Hàm tải data lên để sử dụng data vừa lưu
def load_data():
    file = open('/content/drive/MyDrive/fruit/fruit-train.data', 'rb')

    # dump information to that file
    (images, labels) = pickle.load(file)

    # close the file
    file.close()

    print(images.shape)
    print(labels.shape)


    return images, labels

# Thư mục chứa ảnh test
test_folder = "/content/drive/MyDrive/fruit/Test"

# Hàm tạo test data từ các hình ảnh trong thư mục test đồng thời gán nhãn
def save_test_data(test_folder=test_folder):

    img_size = (64, 64)
    print("Bắt đầu thêm ảnh...")

    images = []
    labels = []
    names = []

    # Đọc các thư mục con trong folder data
    for folder in listdir(test_folder):
        if folder!='.DS_Store':
            print(folder)
            names.append(folder)
            # Đọc các file trong thư mục con và lưu hình vào images, nhãn vào label
            for file in listdir(test_folder  + folder):
                if file!='.DS_Store':
                    images.append(cv2.resize(cv2.imread(test_folder  + folder +"/" + file),dsize=(64,64)))
                    labels.append(folder)

    images = np.array(images)
    labels = np.array(labels)#.reshape(-1,1)

    from sklearn.preprocessing import LabelBinarizer
    encoder = LabelBinarizer()
    labels = encoder.fit_transform(labels)
    print(labels)

    file1 = open('/content/drive/MyDrive/fruit/fruit-test.data','wb')
    file2 = open('/content/drive/MyDrive/fruit/fruit-test-class.data','wb')
    # dump information to that file
    pickle.dump((images,labels), file1)
    pickle.dump(names, file2)
    # close the file
    file1.close()
    file2.close()

    return

# Hàm tải lại test data đã lưu
def load_test_data():
    file = open('/content/drive/MyDrive/fruit/fruit-test.data', 'rb')

    # dump information to that file
    (images, labels) = pickle.load(file)

    # close the file
    file.close()

    print(images.shape)
    print(labels.shape)

    return images, labels

# Hàm tải class của các test data
def load_class():
    file = open('/content/drive/MyDrive/fruit/fruit-test-class.data', 'rb')

    # dump information to that file
    names = pickle.load(file)

    # close the file
    file.close()

    print(len(names))
    
    return names

# Load data và lưu và biến X, y
X,y = load_data()

# Chia tập dữ liệu thành 80% dùng để train, 20% dùng để test
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=100)

print(X_train.shape)
print(y_train.shape)

#Hiển thị ngẫu nhiên 1 dữ liệu
plt.figure(figsize=(64, 64))
plt.imshow(X_train[random.randint(0,len(X_train))])

# Hàm dùng để chuẩn hoá dữ liệu ảnh
def convertImage(img):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.equalizeHist(img)
    img = img /255
    
    return img

# Chuẩn hoá dữ liệu (Normalize the data)
X_train = np.array(list(map(convertImage, X_train)))
X_test = np.array(list(map(convertImage, X_test)))

# Hiển thị ngẫu nhiên 1 dữ liệu đã chuẩn hoá
plt.figure(figsize=(64, 64))
plt.imshow(X_train[random.randint(0,len(X_train))])

# Reshape data để phù hợp với Input_shape của Model
X_train = X_train.reshape(-1, 64, 64, 1)
X_test = X_test.reshape(-1, 64, 64, 1)

#Create model
from keras.models import Sequential
from keras.layers import Dense,Flatten
model = Sequential()
model.add(Flatten(input_shape=(64,64,1)))
model.add(Dense(units=1024, activation = "relu"))
model.add(Dense(units=512, activation = "relu"))
model.add(Dense(units=131, activation = "softmax"))

model.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])
model.summary()

# Huấn luyện model
hist = model.fit(X_train, y_train, epochs = 10, validation_data = (X_test,y_test))

# Load lại test data để model thử predict
X_pred, y_pred = load_test_data()
class_pred = load_class()

# num to predict
num = random.randint(0,len(X_pred))
# Hiển thị hình ảnh predict
plt.figure(figsize=(64, 64))
plt.imshow(X_pred[num])

# Chuẩn hoá dữ liệu predict
X_pred = np.array(list(map(convertImage, X_pred)))

# Predict
X_pred = X_pred.reshape(-1, 64, 64, 1)
y_pred_by_model = model.predict(X_pred[num-1:num])
print('True Class: ', class_pred[np.argmax(y_pred[num])])
print('Predicted Class: ', class_pred[np.argmax(y_pred_by_model)])